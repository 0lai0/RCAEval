#!/usr/bin/env python3
"""
ç°¡åŒ–çš„GRUMVGCæ¸¬è©¦è…³æœ¬
ç›´æ¥æ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½ï¼Œé¿å…ä¾è³´å•é¡Œ
"""

import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.preprocessing import RobustScaler
from sklearn.decomposition import PCA
import networkx as nx

# ç›´æ¥å°å…¥éœ€è¦çš„é¡å’Œå‡½æ•¸
import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

def test_multimodal_data_processor():
    """æ¸¬è©¦å¤šæ¨¡æ…‹æ•¸æ“šè™•ç†å™¨"""
    print("=== Testing MultiModalDataProcessor ===")
    
    # å°å…¥æˆ‘å€‘çš„é¡
    from RCAEval.e2e.grumvgc import MultiModalDataProcessor
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    np.random.seed(42)
    n_samples = 100
    time_points = np.arange(n_samples)
    
    metric_df = pd.DataFrame({
        'time': time_points,
        'service_a_cpu': np.random.normal(0.5, 0.1, n_samples),
        'service_b_cpu': np.random.normal(0.4, 0.1, n_samples),
    })
    
    logts_df = pd.DataFrame({
        'time': time_points,
        'service_a_errors': np.random.poisson(2, n_samples),
        'service_b_errors': np.random.poisson(1, n_samples),
    })
    
    # æ¸¬è©¦è™•ç†å™¨
    processor = MultiModalDataProcessor()
    
    # æ¸¬è©¦å°é½Šæ•¸æ“š
    aligned_data = processor.align_multimodal_data(metric_df, logts_df)
    print(f"âœ… Aligned data keys: {list(aligned_data.keys())}")
    
    # æ¸¬è©¦åˆ†å‰²æ•¸æ“š
    inject_time = 70
    normal_data, anomal_data = processor.split_normal_anomal(aligned_data, inject_time)
    print(f"âœ… Normal data shapes: {[(k, v.shape) for k, v in normal_data.items()]}")
    print(f"âœ… Anomal data shapes: {[(k, v.shape) for k, v in anomal_data.items()]}")
    
    # æ¸¬è©¦ç•°å¸¸æª¢æ¸¬
    combined_df = pd.concat([metric_df.drop(columns=['time']), logts_df.drop(columns=['time'])], axis=1)
    anomaly_scores = processor.detect_anomalies(combined_df)
    print(f"âœ… Anomaly scores: {list(anomaly_scores.keys())[:3]}...")
    
    return True


def test_gru_encoder():
    """æ¸¬è©¦GRUç·¨ç¢¼å™¨"""
    print("\n=== Testing GRUEncoder ===")
    
    from RCAEval.e2e.grumvgc import GRUEncoder
    
    # å‰µå»ºç·¨ç¢¼å™¨
    encoder = GRUEncoder(input_dim=1, hidden_dim=32, output_embedding_dim=64)
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    batch_size = 4
    seq_len = 30
    input_dim = 1
    
    test_input = torch.randn(batch_size, seq_len, input_dim)
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    with torch.no_grad():
        output = encoder(test_input)
    
    print(f"âœ… Input shape: {test_input.shape}")
    print(f"âœ… Output shape: {output.shape}")
    
    assert output.shape == (batch_size, 64), f"Expected (4, 64), got {output.shape}"
    
    return True


def test_infonce_loss():
    """æ¸¬è©¦InfoNCEæå¤±å‡½æ•¸"""
    print("\n=== Testing InfoNCELoss ===")
    
    from RCAEval.e2e.grumvgc import InfoNCELoss
    
    loss_fn = InfoNCELoss(temperature=0.1)
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    batch_size = 4
    embedding_dim = 64
    num_negatives = 5
    
    query = torch.randn(batch_size, embedding_dim)
    positive = torch.randn(batch_size, embedding_dim)
    negatives = torch.randn(batch_size, num_negatives, embedding_dim)
    
    # è¨ˆç®—æå¤±
    loss = loss_fn(query, positive, negatives)
    
    print(f"âœ… Loss value: {loss.item():.4f}")
    
    assert loss.item() > 0, "Loss should be positive"
    
    return True


def test_mvgc_analyzer():
    """æ¸¬è©¦MVGCåˆ†æå™¨"""
    print("\n=== Testing MVGCAnalyzer ===")
    
    from RCAEval.e2e.grumvgc import MVGCAnalyzer
    
    analyzer = MVGCAnalyzer()
    
    # å‰µå»ºæ¸¬è©¦åµŒå…¥æ•¸æ“š
    np.random.seed(42)
    embeddings_dict = {
        'feature_1': np.random.randn(100, 32),
        'feature_2': np.random.randn(100, 32),
        'feature_3': np.random.randn(100, 32),
    }
    
    # æ¸¬è©¦é™ç¶­
    reduced_embeddings = analyzer.reduce_embeddings_to_1d(embeddings_dict)
    print(f"âœ… Reduced embeddings shapes: {[(k, v.shape) for k, v in reduced_embeddings.items()]}")
    
    # æ¸¬è©¦MVGCåˆ†æ
    try:
        causal_edges = analyzer.perform_mvgc(reduced_embeddings)
        print(f"âœ… Found {len(causal_edges)} causal edges")
        if causal_edges:
            print(f"âœ… Sample edge: {causal_edges[0]}")
    except Exception as e:
        print(f"âš ï¸  MVGC analysis failed (expected for random data): {e}")
    
    return True


def test_causal_graph_analyzer():
    """æ¸¬è©¦å› æœåœ–åˆ†æå™¨"""
    print("\n=== Testing CausalGraphAnalyzer ===")
    
    from RCAEval.e2e.grumvgc import CausalGraphAnalyzer
    
    analyzer = CausalGraphAnalyzer()
    
    # å‰µå»ºæ¸¬è©¦å› æœé‚Š
    causal_edges = [
        ('feature_1', 'feature_2', 0.8),
        ('feature_2', 'feature_3', 0.6),
        ('feature_1', 'feature_3', 0.4),
    ]
    
    # æ§‹å»ºå› æœåœ–
    graph = analyzer.build_causal_graph(causal_edges)
    print(f"âœ… Graph nodes: {list(graph.nodes())}")
    print(f"âœ… Graph edges: {list(graph.edges())}")
    
    # å‰µå»ºç•°å¸¸åˆ†æ•¸
    anomaly_scores = {
        'feature_1': 4.5,
        'feature_2': 2.1,
        'feature_3': 3.8,
    }
    
    # æ¸¬è©¦æ ¹å› æ’åº
    ranked_causes = analyzer.rank_root_causes(graph, anomaly_scores)
    print(f"âœ… Ranked root causes: {ranked_causes}")
    
    return True


def test_integration():
    """é›†æˆæ¸¬è©¦ - æ¸¬è©¦å®Œæ•´çš„GRUMVGCæµç¨‹"""
    print("\n=== Integration Test ===")
    
    try:
        # å°å…¥ä¸»å‡½æ•¸
        from RCAEval.e2e.grumvgc import grumvgc
        
        # å‰µå»ºç°¡å–®çš„æ¸¬è©¦æ•¸æ“š
        np.random.seed(42)
        n_samples = 80
        time_points = np.arange(n_samples)
        
        # å¤šæ¨¡æ…‹æ•¸æ“š
        multimodal_data = {
            'metric': pd.DataFrame({
                'time': time_points,
                'cpu_usage': np.random.normal(0.5, 0.1, n_samples),
                'memory_usage': np.random.normal(0.6, 0.1, n_samples),
            }),
            'logts': pd.DataFrame({
                'time': time_points,
                'error_count': np.random.poisson(2, n_samples),
            })
        }
        
        # æ·»åŠ ç•°å¸¸
        inject_time = 60
        multimodal_data['metric']['cpu_usage'][inject_time:] += 0.3
        multimodal_data['logts']['error_count'][inject_time:] += 3
        
        print(f"Created test data with inject_time: {inject_time}")
        
        # é‹è¡ŒGRUMVGCï¼ˆä½¿ç”¨è¼ƒå°çš„åƒæ•¸ä»¥åŠ å¿«æ¸¬è©¦ï¼‰
        result = grumvgc(
            data=multimodal_data,
            inject_time=inject_time,
            dataset="test",
            embedding_dim=16,
            seq_len=15,
            num_epochs=2,
            batch_size=4
        )
        
        print(f"âœ… GRUMVGC completed successfully!")
        print(f"âœ… Number of nodes: {len(result['node_names'])}")
        print(f"âœ… Top root causes: {result['ranks'][:3]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ Starting GRUMVGC Core Tests...\n")
    
    tests = [
        ("MultiModalDataProcessor", test_multimodal_data_processor),
        ("GRUEncoder", test_gru_encoder),
        ("InfoNCELoss", test_infonce_loss),
        ("MVGCAnalyzer", test_mvgc_analyzer),
        ("CausalGraphAnalyzer", test_causal_graph_analyzer),
        ("Integration", test_integration),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            print(f"Running {test_name} test...")
            success = test_func()
            results.append(success)
            if success:
                print(f"âœ… {test_name} test passed\n")
            else:
                print(f"âŒ {test_name} test failed\n")
        except Exception as e:
            print(f"âŒ {test_name} test crashed: {e}\n")
            results.append(False)
    
    # ç¸½çµ
    print("="*50)
    print("ğŸ“Š TEST SUMMARY")
    print("="*50)
    
    passed = sum(results)
    total = len(results)
    
    for i, (test_name, _) in enumerate(tests):
        status = "âœ… PASS" if results[i] else "âŒ FAIL"
        print(f"{test_name}: {status}")
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All core tests passed! GRUMVGC implementation is working correctly.")
    else:
        print(f"âš ï¸  {total - passed} test(s) failed. Please check the implementation.")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 